---
layout: page
title: Research
permalink: /research/
---

For reasoning and knowledge creation, the AI would need an internal model of the world. This paper - [Modelling knowledge representation about matter through causal inference and gradient descent](https://yashsharma79.github.io/files/Modelling knowledge representation about matter through causal inference and gradient descent.pdf). proposes way to build up a simple version of such model and a representation. Prior knowledge of energy, mass and volume is built into the agent. Prediction error is triggered by change in state of objects, which must be resolved by combining causal inference and gradient descent. An external memory is available to the agent in order to compile knowledge that can amortize discovery over multiple inferences.

The environment to learn would be a model that contains hydrogen atoms and ions that will provide the agent with a reference of unit mass, charge and energy. The agent would be equipped with an external memory to record data about the interventions it runs on these atoms. The aim is to generate data with all the interventions that are possible in such a simple but real world. The inference to draw is what behaviour a form of matter would produce under different interventions.

I update this paper regularly. I am very interested about combining error-correcting mechanisms with causal modelling. I am curious about causal inference and automated reasoning.